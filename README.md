# DaisyGANv2
This was meant to be a [Generative adversarial network](https://en.wikipedia.org/wiki/Generative_adversarial_network) which digests character streams.

Following on from DaisyGAN v1 left off; a significant modification was made so that the network would process indexed words form a pre-computed word table.

The word table was generated by taking a number of messages from a random distribution of telegram users, these messages where then sanitised to remove any non-alpha characters, convert uppercase to lowercase characters, and finally split the messages into a list of unique words; this made up the entirety of the word table.

The intention of this word table is that this would be the entire vernacular that the neural net would be capable of understanding and processing, as such, the index of this table was normalised to a -1 to +1 floating-point range before being fed into the neural network. In place of a word being supplied which was no present in the table, a 0 was supplied to the input perceptron at that position in the network, which does actually map to the word "discord".

The network only recognises words of up to 16 characters and each sentence can only have 16 words maximum.

Unfortunately, the performance of this network was still particularly poor.

## Example Usage
```
./cfdgan retrain
./cfdgan "this is an example scentence"
./cfdgan rnd
./cfdgan ask
```
